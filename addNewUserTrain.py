# -*- coding: utf-8 -*-
"""Untitled33.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1nD6vZ07aF6BfmYGgXpThRvIiy3_MRwwr
"""

import os
import sys
import _pickle as cPickle
import numpy as np
from scipy.io.wavfile import read
from sklearn.mixture import GaussianMixture as GMM
from FeatureExtraction import extract_features
import warnings
warnings.filterwarnings("ignore")

newUser = (sys.argv[1])
print('newUser >'+ newUser,'\n')

base_path = "../Biometric-Customer-Authentication/"

#path to training data
#source   ="/content/Speaker-Recognition-GMM/trainingData/"
#source   ="/content/Speaker-Recognition-GMM/addUserData/"
source   = (os.path.join(base_path,"addNewCustomer/"))

#path to store trainged GMM models
#dest = "/content/Speaker-Recognition-GMM/speakerTrainedModelsGMM/"
dest   = (os.path.join(base_path,"speakerTrainedModelsGMM/"))

#training data files names and folders  
#train_file = "/content/Speaker-Recognition-GMM/trainingDataPath.txt"
#train_file = "/content/Speaker-Recognition-GMM/addUserData/Nidhi_Agarwal/addUserTrain.txt"
train_file_1 = (os.path.join(source,'Nidhi_Agarwal_0010/'))
train_file   = (os.path.join(train_file_1,"addUserTrain.txt"))
file_paths = open(train_file,'r')

count = 1
# Extracting features for each speaker (10 files per speakers)
features = np.asarray(())
for path in file_paths:    
    path = path.strip()   
    print (path)
    
    # read the audio
    sr,audio = read(source+path)
    
    # extract 40 dimensional MFCC & delta MFCC features
    vector   = extract_features(audio,sr)
    
    if features.size == 0:
        features = vector
    else:
        features = np.vstack((features, vector))
    # when features of 5 files of speaker are concatenated, then do model training
	# -> if count == 5: --> edited below
    if count == 5:    
        gmm = GMM(n_components = 5, covariance_type='diag',n_init = 3)
        gmm.fit(features)
        # dumping the trained gaussian model
        #picklefile = path.split("_")[0]+".gmm"
        picklefile = path.split("/")[0]+".gmm"
        cPickle.dump(gmm,open(dest + picklefile,'wb'))
        #print ('MFCC + GMM Training modeling completed for speaker:',picklefile," with data point = ",features.shape)
        print ('\nMFCC + GMM Training modeling completed for speaker:',picklefile)   
        features = np.asarray(())
        count = 0
    count = count + 1